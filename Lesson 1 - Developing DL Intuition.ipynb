{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1 - Developing DL Intuition\n",
    "In this lesson we will develop some intuition about how Neural Networks learn to solve a problem based only on a set of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some packages\n",
    "We are using the Python programming language and a set of Machine Learning packages - Importing packages for use is a common task. For this workshop you don't really need to pay that much attention to this step (but you do need to execute the cell) since we are focusing on building models. However the following is a description of what this cell does that you can read if you are interested.\n",
    "\n",
    "### Description of imports (Optional)\n",
    "You don't need to worry about this code as this is not the focus on the workshop but if you are interested in what this next cell does, here is an explaination.\n",
    "\n",
    "|Statement|Meaning|\n",
    "|---|---|\n",
    "|__import tensorflow as tf__ |Tensorflow (from Google) is our main machine learning library and we performs all of the various calculations for us and so hides much of the detailed complexity in Machine Learning. This _import_ statement makes the power of TensorFlow available to us and for convience we will refer to it as __tf__ |\n",
    "|__from tensorflow import keras__ |Tensorflow is quite a low level machine learning library which, while powerful and flexible can be confusing so instead we use another higher level framework called Keras to make our machine learning models more readable and easier to build and test. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import numpy as np__ |Numpy is a Python library for scientific computing and is commonly used for machine learning. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import matplotlib.pyplot as plt__ |To visualise what is happening in our network we will use a set of graphs and MatPlotLib is the standard Python library for producing Graphs so we __import__ this to enable us to make pretty graphs.|\n",
    "| __import lesson1__ |This is a Python libary that contains various functions used and are specific to this workbook. You can look at this code in the GitHub repo (file name _lesson1.py_)|\n",
    "|__%matplotlib inline__| this is a Jupyter Notebook __magic__ commmand that tells the workbook to produce any graphs as part of the workbook and not as pop-up window.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages we need\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the Lesson 1 code\n",
    "import lesson1\n",
    "\n",
    "# Display graphs inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "In this workbook we want to develop an intution about how a Neural Network learns from data in a supervised manner.\n",
    "\n",
    "To develop this intution we will teach a simple network how to predict the cost of a taxi journey based on the number of miles (or kilometers) travelled.\n",
    "\n",
    "In this example we will assume that the cost is __number of miles__ * £0.5 plus a £2 charge. So for a journey of 1 mile the cost would be £3.50. Here is a table of our data.\n",
    "\n",
    "|miles travelled|cost|\n",
    "|---|---|\n",
    "|1|£2.50|\n",
    "|2|£3.00|\n",
    "|3|£3.50|\n",
    "|4|£4.00|\n",
    "|5|£4.50|\n",
    "|6|£5.00|\n",
    "\n",
    "In mathematics terms it is the equation $y = \\frac{1}{2}x + 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our inputs (miles_travelled) and the corresponding output (expected_cost)\n",
    "miles_travelled = np.array([ 1.0, 2.0,  3.0,  4.0,  5.0,  6.0 ], dtype=float)\n",
    "expected_cost   = np.array([ 2.5, 3.0,  3.5,  4.0,  4.5,  5.0 ], dtype=float)\n",
    "\n",
    "# Generate a graph so we can visualise the data\n",
    "lesson1.plotTrainingData(miles_travelled, expected_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a Simple Neural Net to predict the cost\n",
    "In the following cells we will create a very simple Neural Network\n",
    "\n",
    "### Defining a model with Keras\n",
    "Throughout these workbooks we will use Keras to define our Neural Network models. In general we will use what is known as a __Sequential__ model which consists of one or more __layers__ in sequence.\n",
    "\n",
    "The simplist type of layer in Keras is known as a __Dense Layer__ which connects every input to the layer to each of the outputs in the layer. \n",
    "- Each of these __connections__ has a __weight__ which is a numerical value (think of this as importance)\n",
    "- Each Layer has a __Bias__ which adjusts each of the values calculated in the wieghts\n",
    "\n",
    "Our data consists of 6 examples, each with a single input value and we expect a single output value - it's about as simple as it gets.\n",
    "\n",
    "We want to develop an intution about how Neural Networks learn so we will keep our model really simple and have:\n",
    "- A single Dense layer\n",
    "- The Dense layer will consist of a single input unit \n",
    "- The Dense layer will produce a single output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Model\n",
    "model = tf.keras.Sequential()\n",
    "# We have a single Dense Layer with a single unit\n",
    "model.add(keras.layers.Dense(units=1, input_shape=[1]))\n",
    "\n",
    "# Compile the model with an optimizer and loss function\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "\n",
    "# Produce a sumary of our model\n",
    "print(\"\\nModel Summary\\n\")\n",
    "model.summary()\n",
    "\n",
    "# Print the Model's current Weights and Bias values\n",
    "print(\"\\nModel Weights and Bias Terms\\n\")\n",
    "lesson1.displayModelWeightsAndBias(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How good is the model now?\n",
    "Before we train the model, let's see how good it is at predicting the cost from the milages.\n",
    "\n",
    "### Execise\n",
    "Run the cell below and look at the set of Blue Cross - how good is the model currently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "print(\"The Expected cost for a 10 mile journey is £7.00\")\n",
    "print (\"The Predicted cost for a 10 mile journey is £%1.2f\"%(model.predict([10])))\n",
    "\n",
    "# Compare the trained model to the expected\n",
    "lesson1.plotTrainingVsModel(miles_travelled, expected_cost, model)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Train the Model\n",
    "When we train our model we are presenting our network with the set of examples. Typically we need to present the network with the training examples over and over again but let's see how it does when it is trained only once on the data.\n",
    "\n",
    "We do this by using __model.fit__ and specify the inputs and expected outputs and the number of times we want to train the model on (in our case, just once)\n",
    "\n",
    "__Note:__ We are capturing the history of model's learning for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the data for ONE iteration (epochs=1) \n",
    "# and we provide to the model the data we want to train with (miles_travelled) \n",
    "# and the expected values for each traingin example (expected_cost)\n",
    "history = model.fit(miles_travelled, expected_cost, epochs=1)\n",
    "\n",
    "# Store the training history for later analysis\n",
    "all_hist = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "print(\"The Expected cost for a 10 mile journey is £7.00\")\n",
    "print (\"The Predicted cost for a 10 mile journey is £%1.2f\"%(model.predict([10])))\n",
    "\n",
    "# Compare the trained model to the expected\n",
    "lesson1.plotTrainingVsModel(miles_travelled, expected_cost, model)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train for a bit longer\n",
    "Machine Learning is an interative proces, but we can see that even when we train for a single iteration (epoch) our model has improved.\n",
    "\n",
    "So let's train our model a few more times for a total of 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we train for a total of 10 iterations\n",
    "history = model.fit(miles_travelled, expected_cost, epochs=9)\n",
    "\n",
    "all_hist = all_hist + history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "print(\"The Expected cost for a 10 mile journey is £7.00\")\n",
    "print (\"The Predicted cost for a 10 mile journey is £%1.2f\"%(model.predict([10])))\n",
    "\n",
    "# Compare the trained model to the expected\n",
    "lesson1.plotTrainingVsModel(miles_travelled, expected_cost, model)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not quite there so continue to train\n",
    "Our model is improving but it's still not right so let's train for a total of 100 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we train for a total of 100 iterations\n",
    "history = model.fit(miles_travelled, expected_cost, epochs=90)\n",
    "all_hist = all_hist + history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "print(\"The Expected cost for a 10 mile journey is £7.00\")\n",
    "print (\"The Predicted cost for a 10 mile journey is £%1.2f\"%(model.predict([10])))\n",
    "\n",
    "# Compare the trained model to the expected\n",
    "lesson1.plotTrainingVsModel(miles_travelled, expected_cost, model)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Still needs more training\n",
    "Let's train for a total of 1000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we train for a total of 1000 iterations\n",
    "history = model.fit(miles_travelled, expected_cost, epochs=900)\n",
    "\n",
    "all_hist = all_hist + history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction\n",
    "print(\"The Expected cost for a 10 mile journey is £7.00\")\n",
    "print (\"The Predicted cost for a 10 mile journey is £%1.2f\"%(model.predict([10])))\n",
    "\n",
    "# Compare the trained model to the expected\n",
    "lesson1.plotTrainingVsModel(miles_travelled, expected_cost, model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How close are we to the right answer?\n",
    "lesson1.displayTrainingVsPredictedValues(miles_travelled, expected_cost, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our original data the relationship between our input  (x) and our output (y) was $y = \\frac{1}{2}x + 2$\n",
    "\n",
    "If we look at our Weight and Bias terms we can see that they are very close to the co-efficients of this equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Model's current Weights and Bias values\n",
    "print(\"\\nModel Weights and Bias Terms\\n\")\n",
    "lesson1.displayModelWeightsAndBias(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesson1.plotLoss(all_hist, to_epoch=10)\n",
    "lesson1.plotLoss(all_hist, from_epoch=10, to_epoch=100)\n",
    "lesson1.plotLoss(all_hist, from_epoch=100, to_epoch=500)\n",
    "lesson1.plotLoss(all_hist, from_epoch=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something to think about\n",
    "You have seen that Machine Learning is iterative and each iteration (epoch) tries to improve the model by a little bit until it gets good enough. \n",
    " - Why do you think the improvements are small?\n",
    " - Why don't we make bigger adjustments to get good enough quicker?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Observations\n",
    "The following are key observations about Neural Networks to note before we move on\n",
    "1. NNs map inputs to outputs\n",
    "2. NNs __approximate__ some behaviour or relationship between inputs and outputs\n",
    "3. The approximation may (and probably will) differ each time we run the model\n",
    "4. Training a NN is an iterative process that attempts to minimise some error between the expected value and the predicted value.\n",
    "5. Too few iterations leads to a poor approximation.\n",
    "    - more iterations are generally better but after a certain point do not add value\n",
    "    - to many iterations can lead to other issues (Overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
