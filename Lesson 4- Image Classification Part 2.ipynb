{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4 - Image Classification Part 2\n",
    "So in the previous lesson we learned about creating multi-layer networks and how that can improve the learning.\n",
    "\n",
    "In this lesson we will see that simply adding more layers (going deeper) is not always that helpful and so we need to approach the problem in a different way.\n",
    "\n",
    "This lesson will introduce the following new concepts:\n",
    "- Learning features\n",
    "- Convolutional Layers\n",
    "- Max Pooling Layers\n",
    "\n",
    "We will do this using a different image data set call __Fashion-MNIST__. This is a set of different images of Fashion items across 10 different classes (shoes, boots, shirts, dresses etc.). This dataset is harder than the Handwritten digits so we will need to use all we already know solve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some packages\n",
    "We are using the Python programming language and a set of Machine Learning packages - Importing packages for use is a common task. For this workshop you don't really need to pay that much attention to this step (but you do need to execute the cell) since we are focusing on building models. However the following is a description of what this cell does that you can read if you are interested.\n",
    "\n",
    "### Description of imports (Optional)\n",
    "You don't need to worry about this code as this is not the focus on the workshop but if you are interested in what this next cell does, here is an explaination.\n",
    "\n",
    "|Statement|Meaning|\n",
    "|---|---|\n",
    "|__import tensorflow as tf__ |Tensorflow (from Google) is our main machine learning library and we performs all of the various calculations for us and so hides much of the detailed complexity in Machine Learning. This _import_ statement makes the power of TensorFlow available to us and for convience we will refer to it as __tf__ |\n",
    "|__from tensorflow import keras__ |Tensorflow is quite a low level machine learning library which, while powerful and flexible can be confusing so instead we use another higher level framework called Keras to make our machine learning models more readable and easier to build and test. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import numpy as np__ |Numpy is a Python library for scientific computing and is commonly used for machine learning. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import matplotlib.pyplot as plt__ |To visualise what is happening in our network we will use a set of graphs and MatPlotLib is the standard Python library for producing Graphs so we __import__ this to enable us to make pretty graphs.|\n",
    "|__%matplotlib inline__| this is a Jupyter Notebook __magic__ commmand that tells the workbook to produce any graphs as part of the workbook and not as pop-up window.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The following cell contains a set of helper functions that makes our models a little clearer. We will not be going through these functions (since they require Python knowlege) so just make sure you have run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSampleImages(image_data, image_labels, class_labels):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image_data[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(class_labels[image_labels[i]])\n",
    "    plt.show()\n",
    "\n",
    "def printSampleCnnIncorrectImages(source_data, image_labels, class_names, model):\n",
    "  incorrects = np.nonzero(model.predict_classes(source_data).reshape((-1,)) != image_labels)\n",
    "  \n",
    "  plt.figure(figsize=(10,10))\n",
    "  max_items = 25 if len(incorrects[0]) > 25 else len(incorrects[0])\n",
    "  \n",
    "  for i in range(max_items):\n",
    "    incorrect_image_index = incorrects[0][i]\n",
    "    incorrect_image_data = np.array([source_data[incorrect_image_index]])\n",
    "    expected_class = class_names[image_labels[incorrect_image_index]]\n",
    "    preds = model.predict_classes(incorrect_image_data)    \n",
    "    predicted_class = class_names[model.predict_classes(incorrect_image_data)[0]]\n",
    "    errorTitle = \"Expected class: '%s'\\nPredicted class: '%s'\"%(expected_class, predicted_class)\n",
    "\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    #plt.imshow(image_data[incorrect_image_index], cmap=plt.cm.binary)\n",
    "    plt.imshow(source_data[incorrect_image_index].reshape(28,28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(errorTitle)\n",
    "  plt.show()\n",
    "\n",
    "def displayLossAndAccuracy(history):\n",
    "  plt.plot(history.history['loss'], color='red', label='Loss')\n",
    "  plt.plot(history.history['acc'], color='blue', label='Accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(b=True, which='major', color='#666666', linestyle='-')\n",
    "  plt.show()\n",
    "\n",
    "def printSampleIncorrectImages(image_data, image_labels, class_names, model):\n",
    "    incorrects = np.nonzero(model.predict_classes(image_data).reshape((-1,)) != image_labels)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    max_items = 25 if len(incorrects[0]) > 25 else len(incorrects[0])\n",
    "    for i in range(max_items):\n",
    "        incorrect_image_index = incorrects[0][i]\n",
    "        incorrect_image_data = np.array([image_data[incorrect_image_index]])\n",
    "        expected_class = class_names[image_labels[incorrect_image_index]]\n",
    "        predicted_class = class_names[model.predict_classes(incorrect_image_data)[0]]\n",
    "        errorTitle = \"Expected class: '%s'\\nPredicted class: '%s'\"%(expected_class, predicted_class)\n",
    "    \n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(image_data[incorrect_image_index], cmap=plt.cm.binary)\n",
    "        plt.xlabel(errorTitle)\n",
    "    plt.show()\n",
    "\n",
    "def displayConfusionMatrix(expected, predicted):\n",
    "  import seaborn as sn\n",
    "  from sklearn.metrics import confusion_matrix\n",
    "\n",
    "  confusion_matrix = confusion_matrix(y_true = expected, y_pred = predicted)\n",
    "  plt.figure(figsize=(12,8))\n",
    "  ax = plt.subplot()\n",
    "  sn.heatmap(confusion_matrix, annot=True, ax = ax)\n",
    "  ax.set_xlabel('Predicted labels');\n",
    "  ax.set_ylabel('Actual labels'); \n",
    "  ax.set_title('Confusion Matrix'); \n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def displayLayerActivations(cnn_model, image):\n",
    "  import numpy as np\n",
    "  from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "  # Let's define a new Model that will take an image as input, and will output\n",
    "  # intermediate representations for all layers in the previous model after\n",
    "  # the first.\n",
    "  successive_outputs = [layer.output for layer in cnn_model.layers[1:]]\n",
    "  #visualization_model = Model(img_input, successive_outputs)\n",
    "  visualization_model = tf.keras.models.Model(inputs = cnn_model.input,\n",
    "                                              outputs = successive_outputs)\n",
    "  \n",
    "  # Let's run our image through our network, thus obtaining all\n",
    "  # intermediate representations for this image.\n",
    "  image = image.reshape(1,28,28,1)\n",
    "  successive_feature_maps = visualization_model.predict(image)\n",
    "\n",
    "  # These are the names of the layers, so can have them as part of our plot\n",
    "  layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "  # Now let's display our representations\n",
    "  for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "      # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "      n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "      # The feature map has shape (1, size, size, n_features)\n",
    "      size = feature_map.shape[1]\n",
    "      # We will tile our images in this matrix\n",
    "      display_grid = np.zeros((size, size * n_features))\n",
    "      for i in range(n_features):\n",
    "        # Postprocess the feature to make it visually palatable\n",
    "        image = feature_map[0, :, :, i]\n",
    "        image -= image.mean()\n",
    "        image /= image.std()\n",
    "        image *= 64\n",
    "        image += 128\n",
    "        image = np.clip(image, 0, 255).astype('uint8')\n",
    "        # We'll tile each filter into this big horizontal grid\n",
    "        display_grid[:, i * size : (i + 1) * size] = image \n",
    "      # Display the grid\n",
    "      scale = 20. / n_features\n",
    "      plt.figure(figsize=(scale * n_features, scale))\n",
    "      plt.title(layer_name)\n",
    "      plt.grid(False)\n",
    "      #plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "      plt.imshow(display_grid, aspect='auto', cmap=plt.cm.binary)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fashion MNIST dataset\n",
    "The Fashion MNIST dataset is another one of the standard datasets for learning Machine Learning. It contains a set of labelled images across 10 different classes. The images are small (28x28) and greyscale but the are noticably different and most are easy to recognise by a human.\n",
    "\n",
    "As a standard dataset, it comes with Keras and is already split into a Training and Test Set for us.\n",
    "\n",
    "It is a harder problem to solve than the handwritten digits since some classes of images are share similarities. For example, a Shirt and a Pullover have similar shapes.\n",
    "\n",
    "Let's load the dataset and look at some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "((x_train, y_train), (x_test, y_test)) = fashion_mnist.load_data()\n",
    "# This is the list of labels for the classes\n",
    "class_names = [\"t-shirt\", \"trousers\", \"pullover\", \"dress\", \"coat\",\n",
    "           \"sandle\", \"shirt\", \"sneaker\", \"bag\", \"boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images from the Training dataset\")\n",
    "showSampleImages(x_train, y_train, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "As before we will normalise the data so that each pixel has a value between 0 and 1 instead of 0 and 255. \n",
    "\n",
    "Again, this makes the images lighter but does not really change the relative difference between the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Normalised Images\")\n",
    "showSampleImages(x_train, y_train, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Discucss in your groups what you think _Human Level Performance_ would be for this task.\n",
    "\n",
    "Which classifications do you think a human might get confused with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Define your model\n",
    "Discuss in your groups what models you want to try against this data. Think about the:\n",
    "- Number of Hidden Layers in your model\n",
    "- The number of nodes in each of you Hidden Layers\n",
    "- How many epochs you will train for\n",
    "\n",
    "How many nodes do you need in your Output Layer?\n",
    "\n",
    "Come up with enough different models that you can each train a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "\n",
    "# YOUR CHANGES START HERE\n",
    "# Hidden Layers\n",
    "# TODO: Define your network architecture. We've included a sample layer definition for you to \n",
    "# copy and base your layers on. You need to decide how many layers and what side each layer should be\n",
    "# Options include:\n",
    "#    - copy this line to add additional layers\n",
    "#    - Change the number of nodes (from 32) to some other value such as 64, 128 or 256\n",
    "#    - Combine additional layers with different numbers of nodes\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "\n",
    "# TODO: Define how many output nodes you need to classify the images (change None to the number of classes)\n",
    "# Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "# YOUR CHANGES END HERE\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "# YOUR CHANGES START HERE\n",
    "# TODO: Set the number of epochs to train for\n",
    "num_epochs = 20\n",
    "# YOUR CHANGES END HERE\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=num_epochs, validation_split = 0.2, \n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our model\n",
    "Now that we have trained our model (and hopefully the Accuracy of the model is greater than 90%) we can evaluate our model on the _testing dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print (\"Test Loss:\", val_loss)\n",
    "print (\"Test Accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss and accuracty across epochs\n",
    "displayLossAndAccuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the Confusion Matrix\n",
    "test_predictions = model.predict_classes(x_test)\n",
    "for i, label in enumerate(class_names):\n",
    "    print(\"{} = {}\".format(i, label))\n",
    "displayConfusionMatrix(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some of the incorrectly classified images\n",
    "printSampleIncorrectImages(x_test, y_test, class_names, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "In groups, disucss the following:\n",
    "- Which model performed best?\n",
    "- Did your model generalise well to the unseen data?\n",
    "    - Hint look at how close was your Testing Accuracy was to the Training Accuracy?\n",
    "- Does your model appraoch Human Level Performance on this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Think about your current work, social or other situation and how the use of Image Classification could be used for __good__.\n",
    "\n",
    "Work in your teams and:\n",
    "- Identify possible uses for Image Classification in your context\n",
    "- Think about what data you might need and where you can obtain it from\n",
    "- Consider the Ethical and Social implications of doing this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Exercise\n",
    "The following exercise introduces a different type of Network, a Convolutional Neural Network (CNN). This exercise is optional and if time allows; if we do not complete this exercise during the workshop you can complete this in your own time if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Convolution Layers\n",
    "In the models we have been creating we take a 2-D image and flatten it into a single stream of values.\n",
    "\n",
    "However when we flatten the input we \"loose\" some of the spacial information that is contained in the images (e.g. how one pixel or set of pixels relate to each other). With a single list of numbers, does not know how pixels relate to each other so it's harder to \"learn\" spacial information such as lines and patterns. \n",
    "\n",
    "This could be one of the reasons why we seem incapable of doing well on this task. \n",
    "\n",
    "To regain this spacial awareness we need a different types of layers to capture this information.\n",
    "- Convolutional Layers\n",
    "- Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Convolution Layers\n",
    "Convolutions are a technique from Image Processing that are applied to images to perform operations such as:\n",
    "- sharpen an image\n",
    "- Emphisise Veritical, Horizontal or diagonal lines\n",
    "- Emphisise transitions form dark to light\n",
    "\n",
    "In image processing we use specific Convolutions to perform the above operations, but in machine learning we want our model to learn it's own Convolutions from the images so that it can learn basic features (such as lines, shades etc.) and complex features (such as textures, head shapes etc.).\n",
    "\n",
    "A convolution operations works on a filter and scans the image systematically. During _training_ the model is attempting to create a filter that describes some feature of the images it is presented. During _prediction_ the filter is used to detect these features in the image.\n",
    "\n",
    "The following animaation (source https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1) shows how Convolutions work.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*Fw-ehcNBR9byHtho-Rxbtw.gif\" alt=\"Alt text that describes the graphic\" title=\"Title text\" height=\"400\" width=\"400\" />\n",
    "\n",
    "Learning these convolutions allows our model to learn localised features such as perhaps, how do the positions of eyes relate to each other in an image.\n",
    "\n",
    "This can be quite complex to implement but luckily _Keras_ has pre-implemented the Convolution layer so we can simply add this to our model like we have done with the __Dense__ layers\n",
    "\n",
    "We can create Convolution in Keras using:\n",
    "\n",
    "`tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')`\n",
    "\n",
    "Where:\n",
    "- __filters__ is the number of convolution units we want such as 32, 64, 128, 256...\n",
    "    - We can have any number of filters but these are typical values\n",
    "- __kernel_size__ is the size of the grid we want to use such as 1x1, 2x2, 3x3 or 5x5\n",
    "    - The grid can be of any size but these are fairly typical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Pooling layers\n",
    "Pooling layers also systematically scan the image using a filter (_kernel_) but instead of learning some property, they perform some mathematical operations on the data under the grid. These operations can be:\n",
    "- Take the _maximum_ value of the data under the grid. This is known as __Max Pooling__\n",
    "- Take the _minimum_ value of the data under the grid. This is known as __Min Pooling__\n",
    "- Take the _average_ value of the data under the grid. This is known as __Average Pooling__\n",
    "\n",
    "This has the effect of reducing variance and reducing the computational complexity while extracting salient features.\n",
    "\n",
    "A good article on Pooling is at https://medium.com/@bdhuma/which-pooling-method-is-better-maxpooling-vs-minpooling-vs-average-pooling-95fb03f45a9\n",
    "\n",
    "Again Keras makes adding Pooling layers very easy for use:\n",
    "\n",
    "`tf.keras.layers.MaxPooling2D(pool_size=2, stride=2)\n",
    "tf.keras.layers.AveragePooling2D(pool_size=2, stride=2)\n",
    "tf.keras.layers.MinPooling2D(pool_size=2, stride=2)`\n",
    "\n",
    "Where:\n",
    "- __pool_size__ is the size of the grid (in the above cases 2x2)\n",
    "    - We can have non-square pool_sizes such as (1, 3)\n",
    "- __strides__ is the size of the step taken for each pooling operation (in the above cases we step by 2 places each pooling operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a Convolutional Neural Netwok\n",
    "We will now attempt to solve our image classificaiton problem using a Convolutional Neural Network (CNN) and see if we can improve on our previous accuracy score.\n",
    "\n",
    "In this example we will create a small CNN consisting of:\n",
    "- A Convolutional Input layer \n",
    "- A MaxPooling layer\n",
    "- A Convolutional layer (you will specify the number of filters)\n",
    "- A Pooling layer (you will specify whether to use Max, Min or Average Pooling\n",
    "- A Convolutional layer (you will specify the number of filters)\n",
    "- A Dense Layer (you will specify the number of nodes)\n",
    "- An Desnse output layer to classify the images.\n",
    "\n",
    "### Exercise\n",
    "Work in your groups to decide what network archiecture you will use and each train a different network to compare the results.\n",
    "\n",
    "__Notes:__ \n",
    "- when using convolutions it is typical that the number of filters increases as you go deeper into the network so consider patterns such as 32 -> 64 - > 128 rather than decreasing the number of filters.\n",
    "- The more filters you choose the longer the training will take so try not to be too extravagent (at least during the workshop!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), \n",
    "                                     activation='relu', input_shape=(28, 28, 1)))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# YOUR CHANGES START HERE\n",
    "# Layer 1 - TODO\n",
    "#    - specify how many filters you want in the Conv2D layer\n",
    "#    - specify whether you want 'MaxPooling2D', \"AveragePooling2D\" or \"MinPooling2D\" in your pooling\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.25))\n",
    "# Layer 2 - TODO\n",
    "#    - Specify how many filters you want in this layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "# Layer 3 - TODO\n",
    "#    - Specify how may nodes you want in this dense layer\n",
    "cnn_model.add(tf.keras.layers.Flatten())\n",
    "cnn_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Output Layer - we have 10 classes so need 10 nodes\n",
    "cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a bit more data prep to work with Convoltions\n",
    "x_train_cnn = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test_cnn = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "# Train the model (training with Convolutions will be a bit slower \n",
    "# so we don't want to train for too long))\n",
    "num_epochs = 20\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "history = cnn_model.fit(x_train_cnn, y_train, epochs=num_epochs, validation_split = 0.2, \n",
    "                    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = cnn_model.evaluate(x_test_cnn, y_test)\n",
    "print (\"Validation Loss:\", val_loss)\n",
    "print (\"Validation Accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss and accuracty across epochs\n",
    "displayLossAndAccuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the Confusion Matrix\n",
    "test_predictions = cnn_model.predict_classes(x_test_cnn)\n",
    "for i, label in enumerate(class_names):\n",
    "    print(\"{} = {}\".format(i, label))\n",
    "displayConfusionMatrix(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some of the incorrectly classified images\n",
    "printSampleCnnIncorrectImages(x_test_cnn, y_test, class_names, cnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "In groups, disucss the following:\n",
    "- Did the Convolution Model perform better than the Dense Layer Model? If so in what ways?\n",
    "- Did using the Convolution Model change what type of _Confusions_ the model had?\n",
    "- Do you think training the CNN for longer would produce better results?\n",
    "- How well did the CNN generalise to the unseen Test Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Observations\n",
    "The following are key observations to note before we move on\n",
    "1. The relationship between local features can be important and so we need ways to capture this information to enable better learning.\n",
    "    - In this workbook we looked at the use of Convulational Layers which can be used to capture relationships between local features. \n",
    "    - Other types of layers exist that have different properties that are useful in different types of data.\n",
    "2. Models can have good accuracy during training but don't generalise well - this is known as Overfitting.\n",
    "    - there are techniques that we can use to overcome this (such as adding Dropown layers) but this is more advanced that we want to cover in this workshop.\n",
    "3. The more complex the taks the more involved the network architecture can become.\n",
    "    - We will specifically address this in the next lesson."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
