{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6 - Transfer Learning\n",
    "In the previous lessons we have used images that were:\n",
    "- all the same size\n",
    "- the object we are interested in were centered in the image\n",
    "- the images only contained the object of interest\n",
    "- the images were Greyscale (black and white)\n",
    "\n",
    "In addition, previously our images were \"in-memory\" and so we could manipulate the image data without altering the source data. In the real-world we typically have images as files on a file-system and changing the image data (e.g. to normalise the data) affects the source image.\n",
    "\n",
    "These are good for learning but in the real world images tend to be in Colour and somewhat messy. In this lesson we will look at another Standard Dataset (Cats vs Dogs) where the images are colour images of cats and dogs but where:\n",
    "- object of interest (cat or dog) is not always centered\n",
    "- objects may be taken at different angles\n",
    "- other objects may be in the image\n",
    "- the images are of different sizes\n",
    "\n",
    "This is a harder challenge that eithe the Digits or Fashion Datasets and will lead us from building our own networks to using pre-trained networks (Transfer Learning) to boost our ability to classify an image as containing either a cat or dogs.\n",
    "\n",
    "We will also look further into the challenges of testing Machine Learning Systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing some packages\n",
    "We are using the Python programming language and a set of Machine Learning packages - Importing packages for use is a common task. For this workshop you don't really need to pay that much attention to this step (but you do need to execute the cell) since we are focusing on building models. However the following is a description of what this cell does that you can read if you are interested.\n",
    "\n",
    "### Description of imports (Optional)\n",
    "You don't need to worry about this code as this is not the focus on the workshop but if you are interested in what this next cell does, here is an explaination.\n",
    "\n",
    "|Statement|Meaning|\n",
    "|---|---|\n",
    "|__import tensorflow as tf__ |Tensorflow (from Google) is our main machine learning library and we performs all of the various calculations for us and so hides much of the detailed complexity in Machine Learning. This _import_ statement makes the power of TensorFlow available to us and for convience we will refer to it as __tf__ |\n",
    "|__from tensorflow import keras__ |Tensorflow is quite a low level machine learning library which, while powerful and flexible can be confusing so instead we use another higher level framework called Keras to make our machine learning models more readable and easier to build and test. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import numpy as np__ |Numpy is a Python library for scientific computing and is commonly used for machine learning. This _import_ statement makes the Keras framework available to us.|\n",
    "|__import matplotlib.pyplot as plt__ |To visualise what is happening in our network we will use a set of graphs and MatPlotLib is the standard Python library for producing Graphs so we __import__ this to enable us to make pretty graphs.|\n",
    "|__%matplotlib inline__| this is a Jupyter Notebook __magic__ commmand that tells the workbook to produce any graphs as part of the workbook and not as pop-up window.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(\"TensorFlow version is \", tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "The following cell contains a set of helper functions that makes our models a little clearer. We will not be going through these functions (since they require Python knowlege) so just make sure you have run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCatsAndDogsData():\n",
    "  # Download and extract the Data Set\n",
    "  zip_file = tf.keras.utils.get_file(origin=\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\",\n",
    "                                    fname=\"cats_and_dogs_filtered.zip\", extract=True)\n",
    "\n",
    "  # Grab the location of the unzipped data\n",
    "  base_dir, _ = os.path.splitext(zip_file)\n",
    "\n",
    "  # Define the path to the Training and Validation Datasets\n",
    "  train_dir = os.path.join(base_dir, 'train')\n",
    "  validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "  return train_dir, validation_dir\n",
    "\n",
    "def getTrainingDirs(train_dir):\n",
    "  # Directory with our training cat pictures\n",
    "  train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "  print ('Total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "\n",
    "  # Directory with our training dog pictures\n",
    "  train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "  print ('Total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "  return train_cats_dir, train_dogs_dir\n",
    "\n",
    "def getValidationDirs(validation_dir):\n",
    "   # Directory with our validation cat pictures\n",
    "  validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "  print ('Total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "\n",
    "  # Directory with our validation dog pictures\n",
    "  validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "  print ('Total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "\n",
    "  return validation_cats_dir, validation_dogs_dir\n",
    "\n",
    "def getCatsAndDogsImageNames(cats_dir, dogs_dir):\n",
    "  train_cats_names = os.listdir(cats_dir)\n",
    "  train_dogs_names = os.listdir(dogs_dir)\n",
    "\n",
    "  return train_cats_names, train_dogs_names\n",
    "\n",
    "\n",
    "def showImageGrid(image_dir, num_rows=2, num_cols=4):  \n",
    "  image_labels = os.listdir(image_dir)\n",
    "  num_pix = num_rows * num_cols\n",
    "  # Index for iterating over images\n",
    "  pic_index = 0\n",
    "  # Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(num_cols * 4, num_rows * 4)\n",
    "\n",
    "  pic_index += num_pix\n",
    "  next_pix = [os.path.join(image_dir, fname) \n",
    "                  for fname in image_labels[pic_index-num_pix:pic_index]]\n",
    "  \n",
    "  for i, img_path in enumerate(next_pix):\n",
    "    # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(num_rows, num_cols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "def printLossAndAccuracy(history):\n",
    "  acc = history.history['acc']\n",
    "  val_acc = history.history['val_acc']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.plot(acc, label='Training Accuracy')\n",
    "  plt.plot(val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.ylim([min(plt.ylim()),1])\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.plot(loss, label='Training Loss')\n",
    "  plt.plot(val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.ylabel('Cross Entropy')\n",
    "  plt.ylim([0,max(plt.ylim())])\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "We are going to use a smaller version of the \"Cats and Dogs\" dataset, this will enable us to train the model quicker rather than spending hours waiting for the training to complete.\n",
    "\n",
    "The dataset is freely available as a zip file, so we need to download hte file and then unzip it to the filesystem. Each image contains either a Cat or a Dog and is stored as a file.\n",
    "\n",
    "Previously we had a seperate set of data that indicated the labels but typically with image data we use a folder structure to classify the data (i.e. all cat images are in a folder labelled \"Cat\" and all dog images are in a folder called \"Dog\"). \n",
    "\n",
    "The structure of the unzipped images will be:\n",
    "\n",
    "`\\train\n",
    "        \\train\n",
    "                \\cats\n",
    "                \\dogs\n",
    "        \\validation\n",
    "                \\cats\n",
    "                \\dogs`\n",
    "\n",
    "The files under the __train__ folder will be used to train the model. This is split into __cats__ and __dogs__\n",
    "\n",
    "The files under the __validation__ folder will be used to train the model. This is split into __cats__ and __dogs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, validation_dir = getCatsAndDogsData()\n",
    "\n",
    "train_cats_dir, train_dogs_dir = getTrainingDirs(train_dir)\n",
    "validation_cats_dir, validation_dogs_dir = getValidationDirs(validation_dir)\n",
    "\n",
    "train_cats_names, train_dogs_dir = getCatsAndDogsImageNames(train_cats_dir, train_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's looks at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some images from the Training folder\n",
    "print(\"Training Cat Images\")\n",
    "showImageGrid(train_cats_dir, num_rows=2, num_cols=4)\n",
    "\n",
    "print(\"Training Dog Images\")\n",
    "showImageGrid(train_dogs_dir, num_rows=2, num_cols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the images\n",
    "The images in the dataset are of different sizes and use RGB (Red, Green, Blue) values between 0 and 255. As before we need to perform some pre-processing to:\n",
    "- Resize the images to the same size\n",
    "- Normalize the RGB values to the range 0 to 1\n",
    "\n",
    "When training larger datasets we can't or don't really want to just load the images into memory, perform pre-processing and then train with that data. Instead we want to be reading the data in from the file system and perform any pre-processing as needed.\n",
    "\n",
    "Since this is a common scenario, Keras provides Data Generators that are optimized to perform such tasks and so we will set up a Training Data Generator and Validation Data Generator to make our work easier.\n",
    "\n",
    "We will use these generators to do a few things:\n",
    "- Normalise the data to the range 0 to 1\n",
    "- Resize the images to 160 x 160\n",
    "    - Images smaller than 160x160 will be enlarged\n",
    "    - Images larger than 160x160 will be reduced\n",
    "    - Non-Square images will be adjusted to be square\n",
    "- Batch up our images for training\n",
    "\n",
    "The configuration of the Data Generators might seem complex but hopefully will make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want all our images to be re-sized to 160 x 160 pixels\n",
    "image_size = 160\n",
    "\n",
    "# For Training we want to use batches of 32 images at a time\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Data Generator\n",
    "The Training Data Generator will read images in batches from the Training Data folder and perform the pre-processing we need (re-sizing images and normalising the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale all images by 1./255\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "                rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                train_dir,  # Source directory for the training images\n",
    "                target_size = (image_size, image_size),\n",
    "                batch_size = batch_size,\n",
    "                # We are performing a Binary Classification\n",
    "                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Validation Data Generator\n",
    "The Validation Data Generator is almost identical to the Training Data Generator except that we obtain the data from a different folder in the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale all images by 1./255\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Flow validation images in batches of 32 using validation_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "                validation_dir, # Source directory for the validation images\n",
    "                target_size=(image_size, image_size),\n",
    "                batch_size=batch_size,\n",
    "                 # We are performing a Binary Classification\n",
    "                class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Network\n",
    "Use your existing knowledge of Network Models to define a model that you think will be able to successfully classify the images as either a Cat or a Dog.\n",
    "\n",
    "Work in groups to decide the range of network strucutres you want to test and each define a different model.\n",
    "\n",
    "First let's see how well we can classify with a simple Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training using a multi-layer network\n",
    "model = tf.keras.models.Sequential()\n",
    "# Input Layer\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(image_size, image_size, 3)))\n",
    "\n",
    "# YOUR START CHANGES HERE\n",
    "#    Decided how many layers you want and copy the line below to define the layers\n",
    "#    Change the \"None\" to be the number of nodes you want in the layer\n",
    "#model.add(tf.keras.layers.Dense(None, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "\n",
    "\n",
    "# YOUR END CHANGES HERE\n",
    "\n",
    "# Output Layer\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print out a summary of the model\n",
    "mode.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Decide how many epochs you want to train for by changing the value for __epochs__ below and train the model.\n",
    "\n",
    "It is suggested that you don't train for more than 20 epochs due to the time take train the model against the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CHANGES START HERE\n",
    "epochs = 10\n",
    "# YOUR CHANGES END HERE\n",
    "\n",
    "# Stop early if our Validation Loss stagnates\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,  \n",
    "    epochs=epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLossAndAccuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with a CNN\n",
    "The Dense Neural Network probably didn't perform that well- in part this is because the images are more complex (e.g. the head of a cat can appear in any place on the image and be of any size). A Convolutional Network might work better since the way that it scans the image means it can detect features in different parts of the image.\n",
    "\n",
    "So let's create a CNN and see if we can do better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', \n",
    "                                     input_shape=(image_size, image_size, 3)))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(strides=(2, 2)))\n",
    "\n",
    "# Hidden Layers\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D(strides=(2, 2)))\n",
    "\n",
    "\n",
    "# Output Layers\n",
    "cnn_model.add(tf.keras.layers.Flatten())\n",
    "cnn_model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "cnn_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "# Stop early if our Validation Loss stagnates\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=)\n",
    "\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "cnn_history = cnn_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,  \n",
    "    epochs=epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLossAndAccuracy(cnn_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "The problem we are likely having is that when we are training our CNN layers are not deep enough and we are not trianing on a large enough dataset to really capture the local features of an immage.\n",
    "\n",
    "One major trend in Deep Learning is to use general __Pre-trained__ models that have learned quite general features of, for example images, and use this as black box. This provides us with a general feature detector and we then bolt on a smaller network that, based on the outputs of the pre-trained network, learns our specific task. This process is known as __Transfer Learning__ and is likely (for the time being) to be the way that most of us will solve complex machine learning challenges.\n",
    "\n",
    "These Pre-Trained Networks are trained using extermely large amounts of data, using very deep networks and trained for a long time. Training to such a level is likely beyond most of us due to the time and cost of doing this. However there are many such Pre-Trained networks available for free that we can use.\n",
    "\n",
    "## Training using a Pre-Trained Network\n",
    "When we build a network with a Pre-Train network we construct our network such that the Pre-Trained network is the initial layer (even although it's a whole network) and then add our own layers in sequence.\n",
    "\n",
    "During our intial training of the network, do not train the Pre-Trained network (since it's already trained); we _freeze_ that layer and focus our training on the new layers we have added.\n",
    "\n",
    "It may be that this is sufficient to get a really good model. If not we can choose to _unfreeze_ the Pre-Trained network and _fine tune_ the pre-trained network to our specific needs. This process is known as __Fine Tuning__.\n",
    "\n",
    "When Fine-Tuning we have the choice of fine-tuning the whole of the Pre-Trained Network or a portion of the Pre-Trained Network.\n",
    "\n",
    "For Pre-Trained Convolutional Networks, it is the case that early layers are good at detecting more general features such as lines, shadows, textures and so on which are general to most images whereas later layers become more specific and detect more complex features such as faces. So when _fine tuning_ for image problems we often only un-freeze the later levels to train them on our specific requirements.\n",
    "\n",
    "\n",
    "## Pre-trained networks in Keras\n",
    "In the remainder of this lesson we are goign to use a Pre-Trained Network called __MobileNetV2__ which has been trained using a very large dataset called _ImageNet_.\n",
    "\n",
    "Again, Keras makes this quite easy for us to do and we can create our base layer (a Pre-trained network) with a single line: ` tf.keras.applications.MobileNetV2()`.\n",
    "\n",
    "Let's get to work\n",
    "\n",
    "### Creating our Base Layer from MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our base layer (our Pre-Trained Network) \n",
    "# and freeze the model so that it does not change during traiing\n",
    "IMG_SHAPE = (image_size, image_size, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our model \n",
    "Here we will use our base model as the first layer of our model and then create some Dense Layers to learn our specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = tf.keras.Sequential()\n",
    "# Add our base model (the pre-trained network)\n",
    "transfer_model.add(base_model)\n",
    "\n",
    "# Add our model\n",
    "transfer_model.add(keras.layers.GlobalAveragePooling2D())\n",
    "transfer_model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "transfer_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile our model\n",
    "transfer_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train our Transfer Model\n",
    "Training will be much slower than we have seen before because of the size of the network but beacuse we are using transfer learning we shouldn't need to train for very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = validation_generator.n // batch_size\n",
    "\n",
    "transfer_history = transfer_model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              workers=4,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLossAndAccuracy(cnn_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Try a bit of Fine-Tuning\n",
    "To fine tune our model we need to make our base model _trainable_ and then decide how many layers to train.\n",
    "\n",
    "We will find out how many layers there are in our base layer and decide at what point we want to fine tune from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine Tune\n",
    "base_model.trainable = True\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# TODO - you can either accept this value or choose a different layer to start from.\n",
    "fine_tune_from = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have changed our model so let's recomplie and then train for a while longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = new_model.fit_generator(train_generator,\n",
    "                                   steps_per_epoch = steps_per_epoch,\n",
    "                                   epochs=2,\n",
    "                                   workers=4,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLossAndAccuracy(cnn_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "In your teams, consider the task we have been working on (classifying images as containing either a cat or a dog) and consider the following questions:\n",
    "\n",
    "- What would be the Human Level Performance for this task? And how did our model do compared to that expectation?\n",
    "- What cases might confuse a Human in performing this task?\n",
    "- How would we extend our model so that if an image didn't contain a cat or dog that it would predict \"Neither\"? What changes might you need to make to your Data and Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our Model\n",
    "The following cell will allow you to select a file of your own choosing to test our model.\n",
    "\n",
    "### Exercise\n",
    "Think about the task we are trying to solve (detect whether a picture contains a Cat or a Dog) and in your teams consider:\n",
    "- What images might you use to test whether our classifier correctly classifies an image as a cat or dog.\n",
    "- Use the cell below to try some images out \n",
    "    - you can download images to your machine from sites such as PixaBay and run the cell below to load and classify the image.\n",
    "    - NOTE: This only works in a CoLab environment.\n",
    "- Were you able to fool the model in a way that a human would not have been fooled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(300, 300))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  print(classes[0])\n",
    "  if classes[0]>0.5:\n",
    "    print(fn + \" is a human\")\n",
    "  else:\n",
    "    print(fn + \" is a horse\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
